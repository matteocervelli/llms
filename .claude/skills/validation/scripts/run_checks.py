#!/usr/bin/env python3
"""
Automated Validation Runner

Runs comprehensive validation checks for code quality, testing,
coverage, security, and performance. Generates validation reports.

Usage:
    python run_checks.py --all
    python run_checks.py --quality --tests --coverage
    python run_checks.py --all --report validation-report.md

Author: Generated by skill_builder
License: MIT
"""

import argparse
import subprocess
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime


@dataclass
class CheckResult:
    """Result of a validation check."""

    name: str
    passed: bool
    message: str
    details: Optional[str] = None
    duration: float = 0.0


class ValidationRunner:
    """
    Runs validation checks and generates reports.

    Orchestrates various validation tools (pytest, black, mypy, etc.)
    and collects results.
    """

    def __init__(self, project_root: Path):
        """
        Initialize validation runner.

        Args:
            project_root: Root directory of project
        """
        self.project_root = project_root
        self.results: List[CheckResult] = []

    def run_quality_checks(self) -> List[CheckResult]:
        """
        Run code quality checks (Black, mypy, flake8).

        Returns:
            List of check results
        """
        print("Running quality checks...")

        results = []

        # Run Black format check
        result = self._check_black()
        results.append(result)

        # Run mypy type check
        result = self._check_mypy()
        results.append(result)

        # Run flake8 lint
        result = self._check_flake8()
        results.append(result)

        self.results.extend(results)
        return results

    def _check_black(self) -> CheckResult:
        """Run Black format check."""
        start_time = time.time()

        try:
            result = self._run_command(["black", "--check", "src/", "tests/", ".claude/"])
            duration = time.time() - start_time

            if result.returncode == 0:
                return CheckResult(
                    name="Black Format Check",
                    passed=True,
                    message="Code formatting is correct",
                    duration=duration,
                )
            else:
                return CheckResult(
                    name="Black Format Check",
                    passed=False,
                    message="Code formatting issues found",
                    details=result.stdout,
                    duration=duration,
                )
        except FileNotFoundError:
            return CheckResult(
                name="Black Format Check",
                passed=False,
                message="Black not installed (pip install black)",
                duration=time.time() - start_time,
            )

    def _check_mypy(self) -> CheckResult:
        """Run mypy type check."""
        start_time = time.time()

        try:
            result = self._run_command(["mypy", "src/"])
            duration = time.time() - start_time

            if result.returncode == 0:
                return CheckResult(
                    name="Mypy Type Check",
                    passed=True,
                    message="Type checking passed",
                    duration=duration,
                )
            else:
                return CheckResult(
                    name="Mypy Type Check",
                    passed=False,
                    message="Type errors found",
                    details=result.stdout,
                    duration=duration,
                )
        except FileNotFoundError:
            return CheckResult(
                name="Mypy Type Check",
                passed=False,
                message="Mypy not installed (pip install mypy)",
                duration=time.time() - start_time,
            )

    def _check_flake8(self) -> CheckResult:
        """Run flake8 lint check."""
        start_time = time.time()

        try:
            result = self._run_command(["flake8", "src/", "tests/", ".claude/"])
            duration = time.time() - start_time

            if result.returncode == 0:
                return CheckResult(
                    name="Flake8 Lint",
                    passed=True,
                    message="No linting issues",
                    duration=duration,
                )
            else:
                # Count issues
                issues = result.stdout.strip().split("\n") if result.stdout else []
                return CheckResult(
                    name="Flake8 Lint",
                    passed=False,
                    message=f"{len(issues)} linting issues found",
                    details=result.stdout,
                    duration=duration,
                )
        except FileNotFoundError:
            return CheckResult(
                name="Flake8 Lint",
                passed=False,
                message="Flake8 not installed (pip install flake8)",
                duration=time.time() - start_time,
            )

    def run_test_checks(self) -> List[CheckResult]:
        """
        Run test suite.

        Returns:
            List of check results
        """
        print("Running tests...")

        start_time = time.time()

        try:
            result = self._run_command(["pytest", "-v", "--tb=short"])
            duration = time.time() - start_time

            # Parse pytest output for statistics
            if "passed" in result.stdout:
                lines = result.stdout.split("\n")
                for line in lines:
                    if "passed" in line:
                        message = line.strip()
                        break
                else:
                    message = "Tests completed"
            else:
                message = "Test suite executed"

            check_result = CheckResult(
                name="Test Suite",
                passed=result.returncode == 0,
                message=message,
                details=result.stdout if result.returncode != 0 else None,
                duration=duration,
            )

        except FileNotFoundError:
            check_result = CheckResult(
                name="Test Suite",
                passed=False,
                message="Pytest not installed (pip install pytest)",
                duration=time.time() - start_time,
            )

        self.results.append(check_result)
        return [check_result]

    def run_coverage_checks(self, min_coverage: int = 80) -> List[CheckResult]:
        """
        Run coverage analysis.

        Args:
            min_coverage: Minimum coverage percentage required

        Returns:
            List of check results
        """
        print(f"Running coverage checks (minimum: {min_coverage}%)...")

        start_time = time.time()

        try:
            result = self._run_command(
                [
                    "pytest",
                    "--cov=src",
                    f"--cov-fail-under={min_coverage}",
                    "--cov-report=term",
                    "--tb=no",
                ]
            )
            duration = time.time() - start_time

            # Parse coverage percentage from output
            coverage_pct = None
            for line in result.stdout.split("\n"):
                if "TOTAL" in line:
                    parts = line.split()
                    for i, part in enumerate(parts):
                        if part == "TOTAL" and i + 3 < len(parts):
                            try:
                                coverage_pct = int(parts[i + 3].replace("%", ""))
                            except ValueError:
                                pass
                            break

            if coverage_pct is not None:
                passed = coverage_pct >= min_coverage
                message = f"Coverage: {coverage_pct}% (target: {min_coverage}%)"
            else:
                passed = result.returncode == 0
                message = "Coverage check completed"

            check_result = CheckResult(
                name="Test Coverage",
                passed=passed,
                message=message,
                details=result.stdout if not passed else None,
                duration=duration,
            )

        except FileNotFoundError:
            check_result = CheckResult(
                name="Test Coverage",
                passed=False,
                message="Pytest-cov not installed (pip install pytest-cov)",
                duration=time.time() - start_time,
            )

        self.results.append(check_result)
        return [check_result]

    def run_security_checks(self) -> List[CheckResult]:
        """
        Run security checks (dependency scanning).

        Returns:
            List of check results
        """
        print("Running security checks...")

        start_time = time.time()

        try:
            # Try pip-audit first
            result = self._run_command(["pip-audit", "--desc"])
            duration = time.time() - start_time

            if result.returncode == 0:
                check_result = CheckResult(
                    name="Dependency Security",
                    passed=True,
                    message="No known vulnerabilities found",
                    duration=duration,
                )
            else:
                # Count vulnerabilities
                vuln_count = result.stdout.count("Vulnerability")
                check_result = CheckResult(
                    name="Dependency Security",
                    passed=False,
                    message=f"{vuln_count} vulnerabilities found",
                    details=result.stdout,
                    duration=duration,
                )

        except FileNotFoundError:
            # pip-audit not installed, just warn
            check_result = CheckResult(
                name="Dependency Security",
                passed=True,
                message="pip-audit not installed (pip install pip-audit) - skipping",
                duration=time.time() - start_time,
            )

        self.results.append(check_result)
        return [check_result]

    def run_performance_checks(self) -> List[CheckResult]:
        """
        Run performance tests.

        Returns:
            List of check results
        """
        print("Running performance checks...")

        start_time = time.time()

        # Check if performance tests exist
        perf_tests = list(self.project_root.glob("tests/**/test_*performance*.py"))

        if not perf_tests:
            check_result = CheckResult(
                name="Performance Tests",
                passed=True,
                message="No performance tests found (skipping)",
                duration=time.time() - start_time,
            )
        else:
            try:
                result = self._run_command(["pytest", "-v", "-k", "performance", "--tb=short"])
                duration = time.time() - start_time

                if "passed" in result.stdout:
                    lines = result.stdout.split("\n")
                    for line in lines:
                        if "passed" in line:
                            message = line.strip()
                            break
                    else:
                        message = "Performance tests completed"
                else:
                    message = "Performance tests executed"

                check_result = CheckResult(
                    name="Performance Tests",
                    passed=result.returncode == 0,
                    message=message,
                    details=result.stdout if result.returncode != 0 else None,
                    duration=duration,
                )

            except FileNotFoundError:
                check_result = CheckResult(
                    name="Performance Tests",
                    passed=False,
                    message="Pytest not installed",
                    duration=time.time() - start_time,
                )

        self.results.append(check_result)
        return [check_result]

    def _run_command(
        self, command: List[str], cwd: Optional[Path] = None
    ) -> subprocess.CompletedProcess:
        """
        Run command and capture output.

        Args:
            command: Command to run as list of strings
            cwd: Working directory (defaults to project_root)

        Returns:
            CompletedProcess with stdout, stderr, returncode
        """
        return subprocess.run(
            command,
            cwd=cwd or self.project_root,
            capture_output=True,
            text=True,
            timeout=300,  # 5 minute timeout
        )

    def generate_report(self, output_file: Optional[Path] = None) -> str:
        """
        Generate validation report in Markdown format.

        Args:
            output_file: Optional path to write report to

        Returns:
            Report content as string
        """
        print("Generating validation report...")

        # Calculate statistics
        total = len(self.results)
        passed = sum(1 for r in self.results if r.passed)
        failed = total - passed
        total_duration = sum(r.duration for r in self.results)

        # Determine overall status
        all_passed = failed == 0
        status_emoji = "✅" if all_passed else "❌"
        status_text = "PASS" if all_passed else "FAIL"

        # Generate report
        report = f"""# Validation Report

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**Status:** {status_emoji} {status_text}
**Total Checks:** {total}
**Passed:** {passed}
**Failed:** {failed}
**Duration:** {total_duration:.2f}s

---

## Summary

"""

        # Add results by category
        categories = {
            "Quality Checks": [],
            "Testing": [],
            "Coverage": [],
            "Security": [],
            "Performance": [],
        }

        for result in self.results:
            # Categorize result
            name_lower = result.name.lower()
            if "format" in name_lower or "type" in name_lower or "lint" in name_lower:
                category = "Quality Checks"
            elif "coverage" in name_lower:
                category = "Coverage"
            elif "security" in name_lower:
                category = "Security"
            elif "performance" in name_lower:
                category = "Performance"
            else:
                category = "Testing"

            categories[category].append(result)

        # Format each category
        for category, results in categories.items():
            if not results:
                continue

            report += f"\n### {category}\n\n"

            for result in results:
                status = "✅" if result.passed else "❌"
                duration_str = f" ({result.duration:.2f}s)" if result.duration else ""
                report += f"- {status} **{result.name}**: {result.message}{duration_str}\n"

                if result.details and not result.passed:
                    # Limit details to first 20 lines
                    lines = result.details.split("\n")[:20]
                    details = "\n  ".join(lines)
                    report += f"  ```\n  {details}\n  ```\n"

        # Add recommendations
        report += "\n---\n\n## Recommendations\n\n"

        if all_passed:
            report += "✅ All checks passed! Ready to proceed.\n"
        else:
            report += "⚠️ Please address the failed checks before proceeding:\n\n"
            for result in self.results:
                if not result.passed:
                    report += f"- **{result.name}**: {result.message}\n"

        # Write to file if specified
        if output_file:
            output_file.write_text(report)
            print(f"Report written to: {output_file}")

        return report


def main():
    """Main entry point for CLI."""
    parser = argparse.ArgumentParser(
        description="Run automated validation checks",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Run all checks
  python run_checks.py --all

  # Run specific checks
  python run_checks.py --quality --tests --coverage

  # Generate report
  python run_checks.py --all --report validation-report.md

  # Set minimum coverage
  python run_checks.py --coverage --min-coverage 85
        """,
    )

    parser.add_argument("--all", action="store_true", help="Run all validation checks")

    parser.add_argument(
        "--quality",
        action="store_true",
        help="Run quality checks (Black, mypy, flake8)",
    )

    parser.add_argument("--tests", action="store_true", help="Run test suite")

    parser.add_argument("--coverage", action="store_true", help="Run coverage analysis")

    parser.add_argument(
        "--security",
        action="store_true",
        help="Run security checks (dependency scanning)",
    )

    parser.add_argument("--performance", action="store_true", help="Run performance tests")

    parser.add_argument(
        "--min-coverage",
        type=int,
        default=80,
        help="Minimum coverage percentage (default: 80)",
    )

    parser.add_argument(
        "--report",
        type=Path,
        help="Output file for validation report (Markdown)",
    )

    parser.add_argument(
        "--project-root",
        type=Path,
        default=Path.cwd(),
        help="Root directory of project (default: current directory)",
    )

    args = parser.parse_args()

    # Initialize runner
    runner = ValidationRunner(project_root=args.project_root)

    # Determine which checks to run
    run_all = args.all or not any(
        [
            args.quality,
            args.tests,
            args.coverage,
            args.security,
            args.performance,
        ]
    )

    # Run checks
    try:
        if run_all or args.quality:
            runner.run_quality_checks()

        if run_all or args.tests:
            runner.run_test_checks()

        if run_all or args.coverage:
            runner.run_coverage_checks(min_coverage=args.min_coverage)

        if run_all or args.security:
            runner.run_security_checks()

        if run_all or args.performance:
            runner.run_performance_checks()

    except Exception as e:
        print(f"❌ Error running checks: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    # Generate report
    report = runner.generate_report(output_file=args.report)

    # Print report to console if no file specified
    if not args.report:
        print("\n" + report)

    # Exit with appropriate code
    all_passed = all(r.passed for r in runner.results)
    sys.exit(0 if all_passed else 1)


if __name__ == "__main__":
    main()
