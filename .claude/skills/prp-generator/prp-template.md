# Product Requirements Prompt (PRP) Template

**Purpose**: Standard template for Product Requirements Prompt documents generated by design-orchestrator during Phase 2 (Design & Planning).

**Version**: 2.0.0
**Phase**: 2 (Design & Planning)
**Created**: 2025-10-29

---

## Template Usage

This template provides the standard structure for all PRP documents. Fill in each section with information from the analysis document and synthesized design.

**Replace placeholders**:
- `[Feature Name]`: Name of the feature being implemented
- `{issue-number}`: GitHub issue number
- `[Issue Title]`: Full issue title
- `[YYYY-MM-DD]`: Current date
- `[Content]`: Section-specific content

---

## PRP Template

```markdown
# Product Requirements Prompt: [Feature Name] (Issue #{issue-number})

**Date**: [YYYY-MM-DD]
**Designer**: Design Orchestrator (Claude Code)
**Issue**: #{issue-number} - [Issue Title]
**Analysis Document**: /docs/implementation/analysis/feature-{issue-number}-analysis.md

---

**Status**: Ready for Implementation (Phase 3)
**Complexity**: [Low / Medium / High]
**Estimated Effort**: [Hours/Days/Weeks]
**Priority**: [P0 / P1 / P2 / P3]

---

## Executive Summary

[2-3 paragraph overview of the feature and implementation approach]

**Paragraph 1**: [What the feature does and why it's valuable]

**Paragraph 2**: [Architectural approach, key libraries, and implementation strategy]

**Paragraph 3**: [Key considerations, constraints, and success factors]

---

## Requirements Reference

**Source**: [Link to analysis document: /docs/implementation/analysis/feature-{issue-number}-analysis.md]

### Functional Requirements (Summary)
- **[FR-001]**: [Brief description]
- **[FR-002]**: [Brief description]
- **[FR-003]**: [Brief description]

### Non-Functional Requirements (Summary)

#### Performance
- [Key performance requirement 1]
- [Key performance requirement 2]

#### Security
- [Key security requirement 1]
- [Key security requirement 2]

#### Usability
- [Key usability requirement 1]
- [Key usability requirement 2]

#### Scalability
- [Key scalability requirement 1]
- [Key scalability requirement 2]

### Acceptance Criteria (Key Points)
- [ ] [Top acceptance criterion 1]
- [ ] [Top acceptance criterion 2]
- [ ] [Top acceptance criterion 3]
- [ ] [Top acceptance criterion 4]

**Full Requirements**: See analysis document for complete requirements, security assessment, and risk analysis.

---

## Architecture Design

### Component Overview

[High-level architecture description or ASCII diagram]

```
Example:
┌────────────────┐
│  API Layer     │  (FastAPI)
├────────────────┤
│  Service Layer │  (Business Logic)
├────────────────┤
│  Repository    │  (Data Access)
├────────────────┤
│  Database      │  (PostgreSQL)
└────────────────┘
```

### Components

#### Component: [ComponentName]

**Purpose**: [What this component does]

**Responsibilities**:
- [Responsibility 1]
- [Responsibility 2]
- [Responsibility 3]

**Library Integration**:
- **Primary Library**: [LibraryName] v[Version]
- **APIs Used**: `[Library.Class]`, `[Library.method()]`
- **Pattern**: [e.g., Service Layer, Repository, Factory]
- **Dependencies**: [dep-1], [dep-2]

**Implementation Notes**:
- [Important note 1]
- [Important note 2]

**Code Example**:
```python
# Example from library documentation (section X.Y)
[Code snippet showing library usage pattern]
```

**Error Handling**:
- `[LibraryException]` → `[AppException]` → HTTP [Status Code]

[Repeat "Component" section for each architectural component]

### Data Models

#### Model: [ModelName]

**Purpose**: [What this model represents]

**Fields**:
```python
from pydantic import BaseModel, Field
from [library] import [ValidationClass]

class [ModelName](BaseModel):
    """[Model description]"""

    field1: str = Field(..., description="[Description]", min_length=1, max_length=255)
    field2: int = Field(..., description="[Description]", ge=0, le=100)
    field3: Optional[str] = Field(None, description="[Description]")
    # Additional fields...
```

**Validation Rules**:
- `field1`: [Validation description - e.g., "Required, 1-255 characters, alphanumeric"]
- `field2`: [Validation description - e.g., "Required, integer 0-100"]
- `field3`: [Validation description - e.g., "Optional, string"]

**Relationships**:
- `[RelatedModel]`: [Type - e.g., "One-to-Many"] - [Description]

**Library Integration**:
- **Validation**: [e.g., "Pydantic Field validators"]
- **Serialization**: [e.g., "Pydantic .dict() / .json()"]
- **Storage**: [e.g., "SQLAlchemy ORM with declarative_base()"]

[Repeat "Model" section for each data model]

### API Contracts

#### Endpoint: [METHOD] [/path]

**Purpose**: [What this endpoint does]

**Request**:
```python
class [RequestModel](BaseModel):
    field1: type
    field2: type
```
**Example**:
```json
{
  "field1": "value1",
  "field2": "value2"
}
```

**Response**:
```python
class [ResponseModel](BaseModel):
    field1: type
    field2: type
```
**Example**:
```json
{
  "field1": "value1",
  "field2": "value2"
}
```

**Status Codes**:
- `200 OK`: [When this is returned]
- `201 Created`: [When this is returned]
- `400 Bad Request`: [When this is returned - validation errors]
- `401 Unauthorized`: [When this is returned - auth errors]
- `404 Not Found`: [When this is returned - resource not found]
- `500 Internal Server Error`: [When this is returned - unexpected errors]

**Implementation Pattern**:
```python
# FastAPI endpoint (from library docs, section X.Y)
@app.[method]("/path", response_model=[ResponseModel])
def endpoint_name([params: RequestModel]):
    """[Endpoint description]"""
    # Call service layer
    result = service.method([params])
    return [ResponseModel].from_orm(result)
```

**Authentication/Authorization**:
- [Auth requirements - e.g., "Requires valid JWT token, user role"]

[Repeat "Endpoint" section for each API endpoint]

### Data Flow

**Flow: [Flow Name]**

[Description of how data flows through the system]

**Steps**:
1. [Step 1 - e.g., "Client sends POST request to /endpoint"]
2. [Step 2 - e.g., "FastAPI validates request (Pydantic)"]
3. [Step 3 - e.g., "Service layer processes request"]
4. [Step 4 - e.g., "Repository queries database (SQLAlchemy)"]
5. [Step 5 - e.g., "Response serialized and returned"]

**Diagram** (optional):
```
[ASCII or description of data flow]
```

[Repeat "Flow" section for each major data flow]

### Error Handling Strategy

**Exception Hierarchy**:
```python
class AppException(Exception):
    """Base application exception"""
    pass

class NotFoundError(AppException):
    """Resource not found"""
    pass

class ValidationError(AppException):
    """Invalid input data"""
    pass
```

**Library Exception Mapping**:
| Library Exception | App Exception | HTTP Status | User Message |
|-------------------|---------------|-------------|--------------|
| `[Lib.Exception1]` | `NotFoundError` | 404 | "[User-friendly message]" |
| `[Lib.Exception2]` | `ValidationError` | 400 | "[User-friendly message]" |
| `[Lib.Exception3]` | `AppException` | 500 | "Internal server error" |

**Error Handling Pattern**:
```python
try:
    # Library operation
    result = library.method()
except LibraryException as e:
    # Map to app exception
    logger.error(f"Library error: {e}")
    raise AppException("User message") from e
```

---

## Library Documentation

### Library: [LibraryName] v[Version]

**Purpose**: [What this library provides]
**Documentation**: [Link to official docs]
**Repository**: [Link to GitHub/source]
**License**: [License type]

**Installation**:
```bash
pip install [library-name]==[version]
```

**Key APIs Used**:
- `[API1]`: [Description and purpose in this project]
- `[API2]`: [Description and purpose in this project]
- `[API3]`: [Description and purpose in this project]

**Integration Pattern**:
```python
# Example from library documentation
[Code example showing how to use library in this project]
```

**Configuration**:
```python
# Configuration required
[Config code or settings]
```

**Best Practices** (from library docs):
- [Best practice 1]
- [Best practice 2]
- [Best practice 3]

**Known Issues/Workarounds**:
- [Issue 1]: [Workaround]
- [Issue 2]: [Workaround]

**Testing**:
- **Mocking**: [How to mock - e.g., "Use unittest.mock.Mock"]
- **Test Fixtures**: [Any test-specific setup]

[Repeat "Library" section for each library]

---

## Dependencies

### Dependency Tree

```
[Full dependency tree with versions - from Dependency Manager]

Example:
library-a==1.2.3
├── dep-x==2.0.0
│   └── sub-dep==1.0.0
├── dep-y==1.5.0
library-b==2.0.0
├── dep-z==3.0.0
└── dep-x==2.0.0  # Shared with library-a
```

### Installation Commands

**Prerequisites**:
```bash
# Python version
python --version  # Should be >= [X.Y]

# System dependencies (if any)
[System dependency installation commands]
```

**Install Dependencies**:
```bash
# Using pip
pip install -r requirements.txt

# Or using uv (recommended, faster)
uv pip install -r requirements.txt
```

**Install in Order** (if specific order required):
```bash
# Step 1: [Reason]
pip install [packages]

# Step 2: [Reason]
pip install [packages]
```

### Dependency Details

[For each key dependency]

**Dependency**: [dep-name] v[version]
- **Purpose**: [What it provides]
- **Required By**: [Libraries that need it]
- **Version Constraint**: [Why this version - e.g., "2.0.0 resolves conflict"]
- **Optional**: [Yes/No - if optional, when to install]

### Compatibility

**Python Version**: [e.g., "3.9+"]
**Operating System**: [e.g., "Linux, macOS, Windows"]
**Database**: [e.g., "PostgreSQL 12+"]
**Other**: [Any other compatibility notes]

### Resolved Conflicts

[If any dependency conflicts were resolved]

**Conflict**: [Description]
- [Library A] requires: [version constraint A]
- [Library B] requires: [version constraint B]
- **Resolution**: [How resolved - e.g., "Pinned to version X"]
- **Trade-off**: [What we're giving up, if anything]

---

## Implementation Plan

### Overview

Implementation follows a [N]-phase approach: [brief description of phases].

**Total Estimated Effort**: [Hours/Days/Weeks]

### Phase 1: Foundation ([Estimated Time])

**Goal**: [What Phase 1 achieves]

**Tasks**:
1. **[Task Group 1]** ([Time estimate])
   - [ ] [Specific task 1.1]
   - [ ] [Specific task 1.2]
   - [ ] [Specific task 1.3]

2. **[Task Group 2]** ([Time estimate])
   - [ ] [Specific task 2.1]
   - [ ] [Specific task 2.2]

**Files Created**:
- `[filepath1]`: [Description]
- `[filepath2]`: [Description]

**Validation Checkpoint**:
- [ ] [Validation criterion 1]
- [ ] [Validation criterion 2]
- [ ] Phase 1 tests pass

### Phase 2: Core Implementation ([Estimated Time])

**Goal**: [What Phase 2 achieves]

**Tasks**:
1. **[Task Group 1]** ([Time estimate])
   - [ ] [Specific task 1.1]
   - [ ] [Specific task 1.2]

2. **[Task Group 2]** ([Time estimate])
   - [ ] [Specific task 2.1]
   - [ ] [Specific task 2.2]

**Files Created/Modified**:
- `[filepath1]`: [Description]
- `[filepath2]`: [Description]

**Validation Checkpoint**:
- [ ] [Validation criterion 1]
- [ ] [Validation criterion 2]
- [ ] Phase 2 tests pass

### Phase 3: Integration ([Estimated Time])

**Goal**: [What Phase 3 achieves]

**Tasks**:
[Follow same pattern as Phase 1 & 2]

**Validation Checkpoint**:
[Follow same pattern]

### Phase 4: Testing & Validation ([Estimated Time])

**Goal**: Comprehensive testing and validation

**Tasks**:
1. **Test Coverage** ([Time])
   - [ ] Achieve [X]% unit test coverage
   - [ ] All integration tests passing
   - [ ] All e2e tests passing

2. **Security Validation** ([Time])
   - [ ] OWASP Top 10 checks
   - [ ] Input validation testing
   - [ ] Auth/authz testing

3. **Documentation** ([Time])
   - [ ] API docs updated
   - [ ] Code comments complete
   - [ ] README updated

**Final Validation**:
- [ ] All acceptance criteria met
- [ ] All tests passing
- [ ] Coverage targets achieved
- [ ] Security validated
- [ ] Documentation complete

---

## Testing Strategy

### Test Coverage Targets

- **Unit Tests**: [X]% coverage
- **Integration Tests**: All critical paths
- **End-to-End Tests**: All user flows

### Unit Testing

**Framework**: pytest

**Scope**: Individual components in isolation

**Mocking Strategy**:
- [Library1]: [How to mock - e.g., "unittest.mock"]
- [Library2]: [How to mock]
- Database: [How to mock - e.g., "SQLAlchemy in-memory"]

**Test Files**:
```
tests/unit/
├── test_models.py
├── test_repositories.py
├── test_services.py
└── test_[component].py
```

**Example Test**:
```python
def test_[component]_[method]():
    # Arrange
    mock_dep = Mock()
    component = [Component](mock_dep)

    # Act
    result = component.method()

    # Assert
    assert result == expected
    mock_dep.method.assert_called_once()
```

### Integration Testing

**Framework**: pytest + testcontainers

**Scope**: Components with real library instances

**Test Containers**:
- [Container1]: [Purpose - e.g., "Real PostgreSQL database"]
- [Container2]: [Purpose - e.g., "Real Redis instance"]

**Test Files**:
```
tests/integration/
├── test_database_ops.py
├── test_cache_ops.py
└── test_[integration].py
```

### End-to-End Testing

**Framework**: pytest + TestClient (or requests)

**Scope**: Complete API workflows

**Test Files**:
```
tests/e2e/
├── test_api_flows.py
├── test_authentication.py
└── test_[flow].py
```

### Performance Testing

**Tools**: pytest-benchmark, locust

**Target Metrics**:
- [Metric 1]: [Target - e.g., "API response < 200ms (p95)"]
- [Metric 2]: [Target - e.g., "Database query < 50ms"]

### Security Testing

**Checks**:
- [ ] SQL injection prevention
- [ ] XSS prevention
- [ ] CSRF protection
- [ ] Auth bypass attempts
- [ ] Authorization boundaries
- [ ] Secrets management

### Running Tests

```bash
# All tests
pytest

# Unit tests only
pytest tests/unit/

# With coverage
pytest --cov=src --cov-report=html

# Coverage report at: htmlcov/index.html
```

---

## Documentation Requirements

### Code Documentation

- [ ] All functions have docstrings (Google style)
- [ ] Complex logic has inline comments
- [ ] Type hints on all functions
- [ ] README updated with new feature

### API Documentation

- [ ] OpenAPI/Swagger docs generated
- [ ] All endpoints documented
- [ ] Request/response examples
- [ ] Error responses documented

### User Documentation

[If user-facing feature]
- [ ] User guide created
- [ ] Screenshots/examples included
- [ ] FAQ section

### Developer Documentation

- [ ] Architecture diagram updated
- [ ] Setup instructions updated
- [ ] Testing guide updated
- [ ] Deployment guide updated

---

## Success Criteria

### Acceptance Criteria (from Analysis)

- [ ] **AC-001**: [From analysis document]
- [ ] **AC-002**: [From analysis document]
- [ ] **AC-003**: [From analysis document]

### Implementation Criteria

- [ ] All components implemented
- [ ] All libraries integrated
- [ ] All APIs functional
- [ ] Error handling complete

### Testing Criteria

- [ ] Unit test coverage ≥ [X]%
- [ ] Integration tests passing
- [ ] E2E tests passing
- [ ] Performance targets met
- [ ] Security checks passed

### Quality Criteria

- [ ] Linting passed (black, mypy)
- [ ] No security vulnerabilities
- [ ] Code review approved
- [ ] Documentation complete

### Deployment Criteria

- [ ] Deployed to staging
- [ ] Smoke tests passed
- [ ] Deployed to production
- [ ] Monitoring active

---

## Risks & Mitigations

[From analysis document and synthesis]

| Risk | Severity | Probability | Impact | Mitigation |
|------|----------|-------------|--------|------------|
| [Risk 1] | [H/M/L] | [H/M/L] | [Description] | [Strategy] |
| [Risk 2] | [H/M/L] | [H/M/L] | [Description] | [Strategy] |

---

**PRP Complete**: [Date and Time]
**Ready for Phase 3**: Implementation

---
```

## Validation Checklist

Use this checklist to verify PRP completeness:

### Required Sections
- [ ] Header with metadata (date, designer, issue, analysis link, status, complexity, effort, priority)
- [ ] Executive summary (2-3 paragraphs)
- [ ] Requirements reference (FR, NFR, AC summary with link to full analysis)
- [ ] Architecture design (components, models, APIs, data flow, error handling)
- [ ] Library documentation (all libraries with installation, APIs, examples, best practices)
- [ ] Dependencies (tree, installation commands, compatibility, resolved conflicts)
- [ ] Implementation plan (4-5 phases with tasks, files, validation checkpoints)
- [ ] Testing strategy (unit, integration, e2e, performance, security, running tests)
- [ ] Documentation requirements (code, API, user, developer docs)
- [ ] Success criteria (acceptance, implementation, testing, quality, deployment)
- [ ] Risks & mitigations (table with severity, probability, impact, mitigation)

### Content Quality
- [ ] Executive summary is clear and comprehensive
- [ ] All components have library integration details
- [ ] All data models have complete field definitions and validation
- [ ] All API endpoints have request/response examples
- [ ] All libraries have code examples
- [ ] All dependencies are versioned
- [ ] Implementation plan is actionable with specific tasks
- [ ] Testing strategy covers all test types
- [ ] Success criteria are measurable
- [ ] All placeholders replaced with actual content

### Formatting
- [ ] Proper markdown syntax throughout
- [ ] Code blocks have language specified
- [ ] Tables are properly formatted
- [ ] Lists use consistent formatting
- [ ] Headings use proper hierarchy (##, ###, ####)
- [ ] Links are valid

### Length
- [ ] Document is comprehensive (typically 800-1500 lines)
- [ ] No section is unnecessarily verbose
- [ ] All sections provide sufficient detail

---

**Template Version**: 2.0.0
**Last Updated**: 2025-10-29
